# Wayback Machine

Es una gran web donde se puede sacar una cantidad muy importante de información sin necesidad de interactuar con la propia web.

Por ejemplo [https://web.archive.org/web/\*/https://sitioamirar.es/\*](https://web.archive.org/web/\*/https://armada.defensa.gob.es/\*)

Podemos filtrar de distintas formas para encontrar información muy útil, por ejemplo robots.txt antiguos que nos den ideas de otras posibles URLs.

También podemos obtener otros [metadatos de ficheros ofimáticos](dorks-en-buscadores.md#ficheros-y-metadatos) que no hayamos podido encontrar mediante los dorks.

Antiguos formularios de login que se hayan ocultado pero no estén deshabilitados, o portales internos...

Ficheros js que podamos utilizar para realizar análisis estático de estos.

Para poder obtener estas urls tenemos varias herramientas que se pueden utilizar y he obtenido de [https://pentester.land/podcast/2019/03/01/the-bug-hunter-podcast-02.html](https://pentester.land/podcast/2019/03/01/the-bug-hunter-podcast-02.html):

* [Waybackurls](https://github.com/tomnomnom/waybackurls) de Tomnomnom --> Extrae URLs
* [ReconCat](https://github.com/daudmalik06/ReconCat) de Dawood Ikhlaq --> Extrae URLs
* [Curate](https://github.com/EdOverflow/curate) de EdOverflow --> Extrae URLs
* [Chronos](https://github.com/mhmdiaa/chronos) de Mohammed Diaa --> Extrae pequeños segmentos, robots, versiones, subdominios.
* [Waybackrobots.py](https://gist.github.com/mhmdiaa/2742c5e147d49a804b408bfed3d32d07) de de Mohammed Diaa --> Obtener robots
* [Waybackurls.py](https://gist.github.com/mhmdiaa/adf6bff70142e5091792841d4b372050) de Mohammed Diaa --> Obtener Urls

